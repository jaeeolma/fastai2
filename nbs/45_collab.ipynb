{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp collab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai2.tabular.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative filtering\n",
    "\n",
    "> Tools to quickly get the data and train models suitable for collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TabularCollab(TabularPandas):\n",
    "    with_cont=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CollabDataLoaders(DataLoaders):\n",
    "    \"Base `DataLoaders` for collaborative filtering.\"\n",
    "    @delegates(DataLoaders.from_dblock)\n",
    "    @classmethod\n",
    "    def from_df(cls, ratings, valid_pct=0.2, user_name=None, item_name=None, rating_name=None, seed=None, path='.', **kwargs):\n",
    "        \"Create a `DataLoaders` suitable for collaborative filtering from `ratings`.\"\n",
    "        user_name   = ifnone(user_name,  ratings.columns[0])\n",
    "        item_name   = ifnone(item_name,  ratings.columns[1])\n",
    "        rating_name = ifnone(rating_name,ratings.columns[2])\n",
    "        cat_names = [user_name,item_name]\n",
    "        splits = RandomSplitter(valid_pct=valid_pct, seed=seed)(range_of(ratings))\n",
    "        to = TabularCollab(ratings, [Categorify], cat_names, y_names=[rating_name], block_y=TransformBlock(), splits=splits)\n",
    "        return to.dataloaders(path=path, **kwargs)\n",
    "\n",
    "    @delegates(DataLoaders.from_dblock)\n",
    "    @classmethod\n",
    "    def from_csv(cls, csv, valid_pct=0.2, user_name=None, item_name=None, rating_name=None, seed=None, path='.', **kwargs):\n",
    "        \"Create a `DataLoaders` suitable for collaborative filtering from `csv`.\"\n",
    "        return cls.from_df(pd.read_csv(csv), valid_pct, user_name, item_name, rating_name, seed=None, path='.', **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "      <td>1097</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1255504951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>561</td>\n",
       "      <td>924</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1172695223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>157</td>\n",
       "      <td>260</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1291598691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>358</td>\n",
       "      <td>1210</td>\n",
       "      <td>5.0</td>\n",
       "      <td>957481884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>130</td>\n",
       "      <td>316</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1138999234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0      73     1097     4.0  1255504951\n",
       "1     561      924     3.5  1172695223\n",
       "2     157      260     3.5  1291598691\n",
       "3     358     1210     5.0   957481884\n",
       "4     130      316     2.0  1138999234"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.ML_SAMPLE)\n",
    "ratings = pd.read_csv(path/'ratings.csv')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=5)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to = CollabDataLoaders.from_df(ratings, bs=64)\n",
    "to.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>580</td>\n",
       "      <td>4963</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>382</td>\n",
       "      <td>3114</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>130</td>\n",
       "      <td>110</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>212</td>\n",
       "      <td>318</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>306</td>\n",
       "      <td>165</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>544</td>\n",
       "      <td>1089</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>665</td>\n",
       "      <td>2628</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>105</td>\n",
       "      <td>648</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>358</td>\n",
       "      <td>357</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>624</td>\n",
       "      <td>648</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = CollabDataLoaders.from_df(ratings, bs=64)\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = dls.one_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EmbeddingDotBias(Module):\n",
    "    \"Base dot model for collaborative filtering.\"\n",
    "    def __init__(self, n_factors, n_users, n_items, y_range=None):\n",
    "        self.y_range = y_range\n",
    "        (self.u_weight, self.i_weight, self.u_bias, self.i_bias) = [Embedding(*o) for o in [\n",
    "            (n_users, n_factors), (n_items, n_factors), (n_users,1), (n_items,1)\n",
    "        ]]\n",
    "\n",
    "    def forward(self, x):\n",
    "        users,items = x[:,0],x[:,1]\n",
    "        dot = self.u_weight(users)* self.i_weight(items)\n",
    "        res = dot.sum(1) + self.u_bias(users).squeeze() + self.i_bias(items).squeeze()\n",
    "        if self.y_range is None: return res\n",
    "        return torch.sigmoid(res) * (self.y_range[1]-self.y_range[0]) + self.y_range[0]\n",
    "\n",
    "    @classmethod\n",
    "    def from_classes(cls, n_factors, classes, user=None, item=None, y_range=None):\n",
    "        if user is None: user = list(classes.keys())[0]\n",
    "        if item is None: item = list(classes.keys())[1]\n",
    "        res = cls(n_factors, len(classes[user]), len(classes[item]), y_range=y_range)\n",
    "        res.classes,res.user,res.item = classes,user,item\n",
    "        return res\n",
    "\n",
    "    def get_idx(self, arr, is_item=True):\n",
    "        \"Fetch item or user (based on `is_item`) for all in `arr`\"\n",
    "        assert hasattr(self, 'classes'), \"Build your model with `EmbeddingDotBias.from_classes` to use this functionality.\"\n",
    "        classes = self.classes[self.item] if is_item else self.classes[self.user]\n",
    "        c2i = {v:k for k,v in enumerate(classes)}\n",
    "        try: return tensor([c2i[o] for o in arr])\n",
    "        except Exception as e:\n",
    "            print(f\"\"\"You're trying to access {'an item' if is_item else 'a user'} that isn't in the training data.\n",
    "                  If it was in your original data, it may have been split such that it's only in the validation set now.\"\"\")\n",
    "\n",
    "    def bias(self, arr, is_item=True):\n",
    "        \"Bias for item or user (based on `is_item`) for all in `arr`\"\n",
    "        idx = self.get_idx(arr, is_item)\n",
    "        layer = (self.i_bias if is_item else self.u_bias).eval().cpu()\n",
    "        return to_detach(layer(idx).squeeze())\n",
    "\n",
    "    def weight(self, arr, is_item=True):\n",
    "        \"Weight for item or user (based on `is_item`) for all in `arr`\"\n",
    "        idx = self.get_idx(arr, is_item)\n",
    "        layer = (self.i_weight if is_item else self.u_weight).eval().cpu()\n",
    "        return to_detach(layer(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EmbeddingDotBias(50, len(dls.classes['userId']), len(dls.classes['movieId']), y_range=(0,5)).cuda()\n",
    "out = model(x)\n",
    "assert (0 <= out).all() and (out <= 5).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EmbeddingDotBias.from_classes(50, dls.classes, 'userId', 'movieId', y_range=(0,5)).cuda()\n",
    "out = model(x)\n",
    "assert (0 <= out).all() and (out <= 5).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "@delegates()\n",
    "class EmbeddingNN(TabularModel):\n",
    "    \"Subclass `TabularModel` to create a NN suitable for collaborative filtering.\"\n",
    "    def __init__(self, emb_szs, layers, **kwargs):\n",
    "        super().__init__(emb_szs=emb_szs, n_cont=0, out_sz=1, layers=layers, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_szs = get_emb_sz(dls.train_ds, {})\n",
    "model = EmbeddingNN(emb_szs, [50], y_range=(0,5)).cuda()\n",
    "out = model(x)\n",
    "assert (0 <= out).all() and (out <= 5).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Learner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@delegates(Learner.__init__)\n",
    "def collab_learner(dls, n_factors=50, use_nn=False, emb_szs=None, layers=None, config=None, y_range=None, loss_func=None, **kwargs):\n",
    "    \"Create a Learner for collaborative filtering on `data`.\"\n",
    "    emb_szs = get_emb_sz(dls, ifnone(emb_szs, {}))\n",
    "    if loss_func is None: loss_func = MSELossFlat()\n",
    "    if config is None: config = tabular_config()\n",
    "    if y_range is not None: config['y_range'] = y_range\n",
    "    if layers is None: layers = [n_factors]\n",
    "    if use_nn: model = EmbeddingNN(emb_szs=emb_szs, layers=layers, **config)\n",
    "    else:      model = EmbeddingDotBias.from_classes(n_factors, dls.classes, y_range=y_range)\n",
    "    return Learner(dls, model, loss_func=loss_func, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = collab_learner(dls, y_range=(0,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.557128</td>\n",
       "      <td>2.495771</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_torch_core.ipynb.\n",
      "Converted 01_layers.ipynb.\n",
      "Converted 02_data.load.ipynb.\n",
      "Converted 03_data.core.ipynb.\n",
      "Converted 04_data.external.ipynb.\n",
      "Converted 05_data.transforms.ipynb.\n",
      "Converted 06_data.block.ipynb.\n",
      "Converted 07_vision.core.ipynb.\n",
      "Converted 08_vision.data.ipynb.\n",
      "Converted 09_vision.augment.ipynb.\n",
      "Converted 09b_vision.utils.ipynb.\n",
      "Converted 09c_vision.widgets.ipynb.\n",
      "Converted 10_tutorial.pets.ipynb.\n",
      "Converted 11_vision.models.xresnet.ipynb.\n",
      "Converted 12_optimizer.ipynb.\n",
      "Converted 13_callback_core.ipynb.\n",
      "Converted 13a_learner.ipynb.\n",
      "Converted 13b_metrics.ipynb.\n",
      "Converted 14_callback.schedule.ipynb.\n",
      "Converted 14a_callback.data.ipynb.\n",
      "Converted 15_callback.hook.ipynb.\n",
      "Converted 15a_vision.models.unet.ipynb.\n",
      "Converted 16_callback.progress.ipynb.\n",
      "Converted 17_callback.tracker.ipynb.\n",
      "Converted 18_callback.fp16.ipynb.\n",
      "Converted 19_callback.mixup.ipynb.\n",
      "Converted 20_interpret.ipynb.\n",
      "Converted 20a_distributed.ipynb.\n",
      "Converted 21_vision.learner.ipynb.\n",
      "Converted 22_tutorial.imagenette.ipynb.\n",
      "Converted 23_tutorial.transfer_learning.ipynb.\n",
      "Converted 30_text.core.ipynb.\n",
      "Converted 31_text.data.ipynb.\n",
      "Converted 32_text.models.awdlstm.ipynb.\n",
      "Converted 33_text.models.core.ipynb.\n",
      "Converted 34_callback.rnn.ipynb.\n",
      "Converted 35_tutorial.wikitext.ipynb.\n",
      "Converted 36_text.models.qrnn.ipynb.\n",
      "Converted 37_text.learner.ipynb.\n",
      "Converted 38_tutorial.ulmfit.ipynb.\n",
      "Converted 40_tabular.core.ipynb.\n",
      "Converted 41_tabular.data.ipynb.\n",
      "Converted 42_tabular.model.ipynb.\n",
      "Converted 43_tabular.learner.ipynb.\n",
      "Converted 45_collab.ipynb.\n",
      "Converted 50_datablock_examples.ipynb.\n",
      "Converted 60_medical.imaging.ipynb.\n",
      "Converted 65_medical.text.ipynb.\n",
      "Converted 70_callback.wandb.ipynb.\n",
      "Converted 71_callback.tensorboard.ipynb.\n",
      "Converted 72_callback.neptune.ipynb.\n",
      "Converted 97_test_utils.ipynb.\n",
      "Converted 99_pytorch_doc.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
